# pages/4_XÃ¢y_dá»±ng_há»‡_gá»£i_Ã½.py

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import pickle
import os
import matplotlib.pyplot as plt
import seaborn as sns

st.set_page_config(layout="wide")
st.header("ğŸ¯ 4. XÃ‚Y Dá»°NG MÃ” HÃŒNH Gá»¢I Ã (CONTENT-BASED FILTERING)")

# ========== TIÃŠU Äá»€ ==========
st.markdown("""
<div style="background:linear-gradient(90deg, #1E3A8A, #3B82F6); padding:25px; border-radius:10px; color:white; margin-bottom:20px;">
    <h2 style="text-align:center; margin:0;">ğŸ§  MÃ” HÃŒNH CONTENT-BASED FILTERING</h2>
    <p style="text-align:center; margin:10px 0 0 0; font-size:18px;">Sá»­ dá»¥ng TF-IDF + Cosine Similarity</p>
</div>
""", unsafe_allow_html=True)

# ========== Táº¢I Dá»® LIá»†U ==========
@st.cache_data
def load_data():
    """Táº£i dá»¯ liá»‡u phim Ä‘Ã£ lÃ m sáº¡ch"""
    try:
        movies = pd.read_csv("data/movies_final.csv")
        return movies
    except:
        # Táº¡o dá»¯ liá»‡u máº«u náº¿u file khÃ´ng tá»“n táº¡i
        st.error("KhÃ´ng tÃ¬m tháº¥y file dá»¯ liá»‡u. Táº¡o dá»¯ liá»‡u máº«u...")
        data = {
            'movieId': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
            'title': [
                'Toy Story (1995)', 
                'Jumanji (1995)', 
                'Grumpier Old Men (1995)', 
                'Waiting to Exhale (1995)', 
                'Father of the Bride Part II (1995)',
                'Heat (1995)',
                'Sabrina (1995)',
                'Tom and Huck (1995)',
                'Sudden Death (1995)',
                'GoldenEye (1995)'
            ],
            'genres': [
                'Adventure|Animation|Children|Comedy|Fantasy',
                'Adventure|Children|Fantasy',
                'Comedy|Romance',
                'Comedy|Drama|Romance',
                'Comedy',
                'Action|Crime|Thriller',
                'Comedy|Romance',
                'Adventure|Children',
                'Action',
                'Action|Adventure|Thriller'
            ],
            'year': [1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995, 1995],
            'rating_count': [541, 471, 302, 251, 212, 204, 198, 195, 191, 185]
        }
        movies = pd.DataFrame(data)
        movies['content'] = movies['title'] + ' ' + movies['genres'].str.replace('|', ' ')
        return movies

movies = load_data()

# ========== HIá»‚N THá»Š Dá»® LIá»†U ==========
st.markdown("### ğŸ“Š Dá»® LIá»†U Äáº¦U VÃ€O")

col_data1, col_data2 = st.columns([1, 1])

with col_data1:
    st.metric("Tá»•ng sá»‘ phim", f"{len(movies):,}")
    st.metric("Sá»‘ thá»ƒ loáº¡i duy nháº¥t", movies['genres'].str.split('|').explode().nunique())

with col_data2:
    st.metric("NÄƒm Ä‘áº§u tiÃªn", int(movies['year'].min()))
    st.metric("NÄƒm cuá»‘i cÃ¹ng", int(movies['year'].max()))

with st.expander("ğŸ‘€ Xem 10 phim Ä‘áº§u tiÃªn"):
    st.dataframe(movies[['title', 'genres', 'year', 'rating_count']].head(10), 
                 use_container_width=True)

# ========== XÃ‚Y Dá»°NG MÃ” HÃŒNH ==========
st.markdown("---")
st.markdown("## ğŸ”¨ XÃ‚Y Dá»°NG MÃ” HÃŒNH")

# Tab cho tá»«ng bÆ°á»›c
tab1, tab2, tab3, tab4 = st.tabs([
    "1. Chuáº©n bá»‹ dá»¯ liá»‡u", 
    "2. TF-IDF Vectorizer", 
    "3. Cosine Similarity", 
    "4. Demo gá»£i Ã"
])

# ========== TAB 1: CHUáº¨N Bá»Š Dá»® LIá»†U ==========
with tab1:
    st.markdown("### ğŸ“ BÆ¯á»šC 1: CHUáº¨N Bá»Š Dá»® LIá»†U")
    
    col_prep1, col_prep2 = st.columns(2)
    
    with col_prep1:
        st.markdown("""
        #### Váº¥n Ä‘á»:
        - Dá»¯ liá»‡u vÄƒn báº£n (text) khÃ´ng thá»ƒ tÃ­nh toÃ¡n trá»±c tiáº¿p
        - Cáº§n chuyá»ƒn Ä‘á»•i thÃ nh vector sá»‘
        
        #### Giáº£i phÃ¡p:
        - Táº¡o cá»™t `content` káº¿t há»£p:
          - Title cá»§a phim
          - Thá»ƒ loáº¡i (genres)
        - Chuáº©n hÃ³a text (lowercase, xá»­ lÃ½ Ä‘áº·c biá»‡t)
        """)
        
        # Hiá»ƒn thá»‹ vÃ­ dá»¥ content
        if 'content' not in movies.columns:
            movies['content'] = movies['title'].fillna('') + ' ' + movies['genres'].str.replace('|', ' ', regex=False)
        
        st.markdown("#### VÃ­ dá»¥ cá»™t `content`:")
        st.code(movies['content'].head(3).tolist())
    
    with col_prep2:
        st.markdown("#### Code xá»­ lÃ½:")
        st.code("""
# Chuáº©n bá»‹ dá»¯ liá»‡u cho TF-IDF
def prepare_content(movies_df):
    # Táº¡o cá»™t content: title + genres
    movies_df['content'] = (
        movies_df['title'].fillna('') + ' ' + 
        movies_df['genres'].str.replace('|', ' ', regex=False)
    )
    
    # Chuyá»ƒn thÃ nh lowercase
    movies_df['content'] = movies_df['content'].str.lower()
    
    # Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t
    movies_df['content'] = movies_df['content'].str.replace(r'[^\w\s]', ' ', regex=True)
    
    return movies_df

# Ãp dá»¥ng hÃ m
movies = prepare_content(movies)
print(f"Máº«u content: {movies['content'].iloc[0]}")
        """, language="python")
        
        if st.button("â–¶ï¸ Ãp dá»¥ng xá»­ lÃ½", key="prep_btn"):
            # Ãp dá»¥ng xá»­ lÃ½
            movies['content'] = movies['title'].fillna('') + ' ' + movies['genres'].str.replace('|', ' ', regex=False)
            movies['content'] = movies['content'].str.lower()
            movies['content'] = movies['content'].str.replace(r'[^\w\s]', ' ', regex=True)
            
            st.success("âœ… ÄÃ£ chuáº©n bá»‹ xong dá»¯ liá»‡u!")
            st.write("**Máº«u content sau xá»­ lÃ½:**")
            st.write(movies['content'].iloc[0][:100] + "...")

# ========== TAB 2: TF-IDF VECTORIZER ==========
with tab2:
    st.markdown("### ğŸ”¢ BÆ¯á»šC 2: TF-IDF VECTORIZER")
    
    col_tfidf1, col_tfidf2 = st.columns(2)
    
    with col_tfidf1:
        st.markdown("""
        #### TF-IDF lÃ  gÃ¬?
        
        **TF (Term Frequency):**
        - Táº§n suáº¥t tá»« xuáº¥t hiá»‡n trong vÄƒn báº£n
        - Tá»« cÃ ng xuáº¥t hiá»‡n nhiá»u cÃ ng quan trá»ng
        
        **IDF (Inverse Document Frequency):**
        - Äá»™ hiáº¿m cá»§a tá»« trong toÃ n bá»™ corpus
        - Tá»« xuáº¥t hiá»‡n á»Ÿ nhiá»u vÄƒn báº£n sáº½ cÃ³ trá»ng sá»‘ tháº¥p
        
        #### Æ¯u Ä‘iá»ƒm:
        - ÄÃ¡nh trá»ng sá»‘ cho tá»« quan trá»ng
        - Giáº£m trá»ng sá»‘ tá»« phá»• biáº¿n (stopwords)
        - Chuyá»ƒn text â†’ vector sá»‘
        """)
        
        # Cáº¥u hÃ¬nh TF-IDF
        st.markdown("#### âš™ï¸ Cáº¥u hÃ¬nh:")
        max_features = st.slider("Sá»‘ features tá»‘i Ä‘a:", 100, 10000, 5000, 100)
        ngram_range = st.selectbox("N-gram range:", ["(1,1) - Unigram", "(1,2) - Unigram+Bigram", "(1,3) - Unigram+Bigram+Trigram"])
        
        # Map selection
        ngram_map = {
            "(1,1) - Unigram": (1, 1),
            "(1,2) - Unigram+Bigram": (1, 2),
            "(1,3) - Unigram+Bigram+Trigram": (1, 3)
        }
    
    with col_tfidf2:
        st.markdown("#### Code TF-IDF:")
        st.code(f"""
from sklearn.feature_extraction.text import TfidfVectorizer

# Khá»Ÿi táº¡o TF-IDF Vectorizer
tfidf = TfidfVectorizer(
    stop_words='english',      # Loáº¡i bá» stopwords tiáº¿ng Anh
    max_features={max_features},     # Giá»›i háº¡n sá»‘ features
    ngram_range={ngram_map[ngram_range]},  # XÃ©t 1-N tá»« liÃªn tiáº¿p
    min_df=2,                  # Tá»« pháº£i xuáº¥t hiá»‡n Ã­t nháº¥t 2 láº§n
    max_df=0.95                # Tá»‘i Ä‘a 95% documents
)

# Ãp dá»¥ng lÃªn dá»¯ liá»‡u
tfidf_matrix = tfidf.fit_transform(movies['content'])

print(f"Shape cá»§a TF-IDF matrix: {{tfidf_matrix.shape}}")
print(f"Sá»‘ tá»« vá»±ng: {{len(tfidf.get_feature_names_out())}}")
        """, language="python")
        
        if st.button("â–¶ï¸ Cháº¡y TF-IDF", key="tfidf_btn"):
            with st.spinner("Äang cháº¡y TF-IDF..."):
                try:
                    # Ãp dá»¥ng TF-IDF
                    ngram = ngram_map[ngram_range]
                    tfidf = TfidfVectorizer(
                        stop_words='english',
                        max_features=max_features,
                        ngram_range=ngram,
                        min_df=2,
                        max_df=0.95
                    )
                    
                    # Táº¡o content náº¿u chÆ°a cÃ³
                    if 'content' not in movies.columns:
                        movies['content'] = movies['title'].fillna('') + ' ' + movies['genres'].str.replace('|', ' ', regex=False)
                    
                    tfidf_matrix = tfidf.fit_transform(movies['content'])
                    
                    st.success("âœ… TF-IDF hoÃ n thÃ nh!")
                    st.metric("Shape TF-IDF matrix", f"{tfidf_matrix.shape[0]} x {tfidf_matrix.shape[1]}")
                    st.metric("Sá»‘ tá»« vá»±ng", len(tfidf.get_feature_names_out()))
                    
                    # Hiá»ƒn thá»‹ má»™t sá»‘ tá»« vá»±ng
                    with st.expander("ğŸ‘ï¸ Xem má»™t sá»‘ tá»« vá»±ng (features)"):
                        features = tfidf.get_feature_names_out()[:50]
                        st.write(", ".join(features))
                        
                    # LÆ°u vÃ o session state Ä‘á»ƒ dÃ¹ng sau
                    st.session_state['tfidf_matrix'] = tfidf_matrix
                    st.session_state['tfidf'] = tfidf
                    
                except Exception as e:
                    st.error(f"Lá»—i: {e}")

# ========== TAB 3: COSINE SIMILARITY ==========
with tab3:
    st.markdown("### ğŸ“ BÆ¯á»šC 3: COSINE SIMILARITY")
    
    col_cos1, col_cos2 = st.columns(2)
    
    with col_cos1:
        st.markdown("""
        #### Cosine Similarity lÃ  gÃ¬?
        
        **CÃ´ng thá»©c:**
        ```
        similarity = cos(Î¸) = (AÂ·B) / (||A|| * ||B||)
        ```
        
        **Ã nghÄ©a:**
        - Äo gÃ³c giá»¯a 2 vector
        - Range: [-1, 1]
        - 1: HoÃ n toÃ n giá»‘ng nhau
        - 0: KhÃ´ng liÃªn quan
        - -1: HoÃ n toÃ n ngÆ°á»£c nhau
        
        **á»¨ng dá»¥ng:**
        - So sÃ¡nh Ä‘á»™ giá»‘ng nhau giá»¯a cÃ¡c phim
        - TÃ¬m phim tÆ°Æ¡ng tá»± dá»±a trÃªn content
        """)
        
        # Visualization
        st.markdown("#### ğŸ¨ Minh há»a:")
        
        fig, ax = plt.subplots(figsize=(6, 4))
        
        # Váº½ gÃ³c giá»¯a 2 vector
        ax.arrow(0, 0, 0.8, 0.6, head_width=0.05, head_length=0.1, fc='blue', ec='blue', label='Vector A (Phim 1)')
        ax.arrow(0, 0, 0.4, 0.8, head_width=0.05, head_length=0.1, fc='red', ec='red', label='Vector B (Phim 2)')
        
        # GÃ³c giá»¯a 2 vector
        ax.text(0.3, 0.3, 'Î¸', fontsize=20)
        
        ax.set_xlim(0, 1)
        ax.set_ylim(0, 1)
        ax.set_xlabel('Feature 1')
        ax.set_ylabel('Feature 2')
        ax.set_title('Cosine Similarity = cos(Î¸)')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        st.pyplot(fig)
    
    with col_cos2:
        st.markdown("#### Code Cosine Similarity:")
        st.code("""
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# TÃ­nh cosine similarity
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

print(f"Shape cá»§a Cosine Similarity matrix: {cosine_sim.shape}")
print(f"Kiá»ƒu dá»¯ liá»‡u: {cosine_sim.dtype}")

# Ma tráº­n Ä‘á»‘i xá»©ng
print(f"Äá»‘i xá»©ng: {np.allclose(cosine_sim, cosine_sim.T)}")

# Diagonal = 1 (tá»± so vá»›i chÃ­nh nÃ³)
print(f"ÄÆ°á»ng chÃ©o toÃ n 1: {np.allclose(np.diag(cosine_sim), 1)}")

# Láº¥y similarity cho má»™t phim cá»¥ thá»ƒ
movie_idx = 0  # Toy Story
similarities = cosine_sim[movie_idx]
print(f"Similarities vá»›i phim Ä‘áº§u tiÃªn: {similarities[:5]}")
        """, language="python")
        
        if st.button("â–¶ï¸ TÃ­nh Cosine Similarity", key="cos_btn"):
            if 'tfidf_matrix' not in st.session_state:
                st.warning("âš ï¸ Cáº§n cháº¡y TF-IDF trÆ°á»›c!")
            else:
                with st.spinner("Äang tÃ­nh Cosine Similarity..."):
                    try:
                        # TÃ­nh cosine similarity
                        from sklearn.metrics.pairwise import cosine_similarity
                        cosine_sim = cosine_similarity(st.session_state['tfidf_matrix'])
                        
                        st.success("âœ… Cosine Similarity hoÃ n thÃ nh!")
                        st.metric("Shape matrix", f"{cosine_sim.shape[0]} x {cosine_sim.shape[1]}")
                        
                        # Hiá»ƒn thá»‹ vÃ­ dá»¥
                        st.markdown("#### ğŸ¯ VÃ­ dá»¥: Similarity matrix (5x5 Ä‘áº§u tiÃªn)")
                        st.dataframe(
                            pd.DataFrame(
                                cosine_sim[:5, :5],
                                index=movies['title'].head(5),
                                columns=movies['title'].head(5)
                            ).round(3),
                            use_container_width=True
                        )
                        
                        # LÆ°u vÃ o session state
                        st.session_state['cosine_sim'] = cosine_sim
                        
                        # LÆ°u vÃ o file
                        with open('data/cosine_sim.pkl', 'wb') as f:
                            pickle.dump(cosine_sim, f)
                        st.info("ğŸ’¾ ÄÃ£ lÆ°u cosine_sim vÃ o data/cosine_sim.pkl")
                        
                    except Exception as e:
                        st.error(f"Lá»—i: {e}")

# ========== TAB 4: DEMO Gá»¢I Ã ==========
with tab4:
    st.markdown("### ğŸ¬ BÆ¯á»šC 4: DEMO Há»† THá»NG Gá»¢I Ã")
    
    col_demo1, col_demo2 = st.columns([3, 2])
    
    with col_demo1:
        st.markdown("#### ğŸ” TÃŒM PHIM TÆ¯Æ NG Tá»°")
        
        # Chá»n phim gá»‘c
        base_movie = st.selectbox(
            "Chá»n phim báº¡n thÃ­ch:",
            movies['title'].tolist(),
            index=0,
            help="Chá»n má»™t phim Ä‘á»ƒ tÃ¬m phim tÆ°Æ¡ng tá»±"
        )
        
        # Sá»‘ phim tÆ°Æ¡ng tá»±
        num_recommendations = st.slider("Sá»‘ phim tÆ°Æ¡ng tá»±:", 3, 20, 10)
        
        # TÃ¹y chá»n filter
        st.markdown("##### ğŸ›ï¸ TÃ¹y chá»n lá»c")
        col_filter1, col_filter2 = st.columns(2)
        with col_filter1:
            min_similarity = st.slider("Äá»™ tÆ°Æ¡ng Ä‘á»“ng tá»‘i thiá»ƒu:", 0.0, 1.0, 0.3, 0.05)
        with col_filter2:
            same_year = st.checkbox("Chá»‰ phim cÃ¹ng nÄƒm", value=False)
    
    with col_demo2:
        st.markdown("#### ğŸ“Š THÃ”NG TIN PHIM")
        
        if base_movie:
            movie_info = movies[movies['title'] == base_movie]
            if len(movie_info) > 0:
                movie = movie_info.iloc[0]
                
                st.write(f"**ğŸ¬ {movie['title']}**")
                st.write(f"ğŸ­ **Thá»ƒ loáº¡i:** {movie['genres']}")
                st.write(f"ğŸ“… **NÄƒm:** {int(movie['year'])}")
                st.write(f"â­ **Sá»‘ rating:** {movie['rating_count']:,}")
                
                # Highlight genres
                genres_list = movie['genres'].split('|')
                st.write("**ğŸ·ï¸ Tags:**")
                for genre in genres_list:
                    st.markdown(f"`{genre}` ", unsafe_allow_html=True)
    
    # NÃºt tÃ¬m kiáº¿m
    if st.button("ğŸ” TÃŒM PHIM TÆ¯Æ NG Tá»°", type="primary", use_container_width=True):
        if 'cosine_sim' not in st.session_state:
            st.warning("âš ï¸ Cáº§n tÃ­nh Cosine Similarity trÆ°á»›c!")
        else:
            try:
                # TÃ¬m index cá»§a phim
                movie_idx = movies[movies['title'] == base_movie].index[0]
                
                # Láº¥y similarity scores
                sim_scores = list(enumerate(st.session_state['cosine_sim'][movie_idx]))
                
                # Sáº¯p xáº¿p theo similarity
                sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
                
                # Láº¥y top N (bá» qua chÃ­nh nÃ³)
                sim_scores = sim_scores[1:num_recommendations*2]
                
                # Lá»c theo similarity
                filtered_scores = []
                for idx, score in sim_scores:
                    if score >= min_similarity:
                        if same_year:
                            if movies.iloc[idx]['year'] == movies.iloc[movie_idx]['year']:
                                filtered_scores.append((idx, score))
                        else:
                            filtered_scores.append((idx, score))
                    
                    if len(filtered_scores) >= num_recommendations:
                        break
                
                # Hiá»ƒn thá»‹ káº¿t quáº£
                if filtered_scores:
                    st.success(f"### ğŸ¯ TÃŒM THáº¤Y {len(filtered_scores)} PHIM TÆ¯Æ NG Tá»°")
                    
                    # Táº¡o DataFrame káº¿t quáº£
                    results = []
                    for i, (idx, score) in enumerate(filtered_scores, 1):
                        movie = movies.iloc[idx]
                        results.append({
                            'STT': i,
                            'Phim': movie['title'],
                            'Thá»ƒ loáº¡i': movie['genres'],
                            'NÄƒm': int(movie['year']),
                            'Äá»™ tÆ°Æ¡ng Ä‘á»“ng': f"{score:.3f}",
                            'Sá»‘ rating': f"{movie['rating_count']:,}"
                        })
                    
                    results_df = pd.DataFrame(results)
                    
                    # Hiá»ƒn thá»‹ dáº¡ng báº£ng
                    st.dataframe(
                        results_df,
                        use_container_width=True,
                        hide_index=True,
                        column_config={
                            "Äá»™ tÆ°Æ¡ng Ä‘á»“ng": st.column_config.ProgressColumn(
                                format="%.3f",
                                min_value=0,
                                max_value=1
                            )
                        }
                    )
                    
                    # Hiá»ƒn thá»‹ dáº¡ng visual
                    st.markdown("#### ğŸ“Š BIá»‚U Äá»’ Äá»˜ TÆ¯Æ NG Äá»’NG")
                    
                    # Táº¡o biá»ƒu Ä‘á»“
                    fig, ax = plt.subplots(figsize=(10, 6))
                    movies_list = [movies.iloc[idx]['title'][:20] + "..." for idx, _ in filtered_scores]
                    similarity_scores = [score for _, score in filtered_scores]
                    
                    colors = plt.cm.YlOrRd(similarity_scores)  # MÃ u theo Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng
                    
                    bars = ax.barh(movies_list, similarity_scores, color=colors)
                    ax.set_xlabel('Äá»™ tÆ°Æ¡ng Ä‘á»“ng (Cosine Similarity)')
                    ax.set_title('Top phim tÆ°Æ¡ng tá»± vá»›i "' + base_movie[:30] + '"')
                    ax.set_xlim(0, 1)
                    
                    # ThÃªm giÃ¡ trá»‹ trÃªn má»—i bar
                    for bar, score in zip(bars, similarity_scores):
                        ax.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,
                               f'{score:.3f}', va='center')
                    
                    plt.tight_layout()
                    st.pyplot(fig)
                    
                    # Thá»‘ng kÃª
                    avg_similarity = np.mean(similarity_scores)
                    st.metric("Äá»™ tÆ°Æ¡ng Ä‘á»“ng trung bÃ¬nh", f"{avg_similarity:.3f}")
                    
                else:
                    st.warning("KhÃ´ng tÃ¬m tháº¥y phim tÆ°Æ¡ng tá»± nÃ o Ä‘áº¡t ngÆ°á»¡ng similarity.")
                    
            except Exception as e:
                st.error(f"Lá»—i: {e}")

# ========== Tá»”NG Káº¾T MÃ” HÃŒNH ==========
st.markdown("---")
st.markdown("## ğŸ† Tá»”NG Káº¾T MÃ” HÃŒNH")

col_summary1, col_summary2 = st.columns(2)

with col_summary1:
    st.markdown("""
    ### âœ… Æ¯U ÄIá»‚M MÃ” HÃŒNH
    
    1. **KhÃ´ng cáº§n dá»¯ liá»‡u ngÆ°á»i dÃ¹ng:**
       - Chá»‰ cáº§n metadata cá»§a phim
       - KhÃ´ng bá»‹ cold-start problem
       
    2. **Giáº£i thÃ­ch Ä‘Æ°á»£c:**
       - Dá»±a trÃªn thá»ƒ loáº¡i, ná»™i dung
       - User hiá»ƒu táº¡i sao Ä‘Æ°á»£c gá»£i Ã
       
    3. **ÄÆ¡n giáº£n, hiá»‡u quáº£:**
       - Dá»… triá»ƒn khai
       - TÃ­nh toÃ¡n nhanh
       - PhÃ¹ há»£p vá»›i há»‡ thá»‘ng nhá»
    """)

with col_summary2:
    st.markdown("""
    ### âš ï¸ Háº N CHáº¾ & GIáº¢I PHÃP
    
    1. **Limited diversity:**
       - Gá»£i Ã phim quÃ¡ giá»‘ng nhau
       - **Giáº£i phÃ¡p:** ThÃªm serendipity factor
       
    2. **KhÃ´ng cÃ¡ nhÃ¢n hÃ³a sÃ¢u:**
       - Má»i user cÃ¹ng xem 1 phim sáº½ nháº­n gá»£i Ã giá»‘ng nhau
       - **Giáº£i phÃ¡p:** Káº¿t há»£p Collaborative Filtering
       
    3. **Phá»¥ thuá»™c metadata:**
       - Cáº§n metadata cháº¥t lÆ°á»£ng
       - **Giáº£i phÃ¡p:** LÃ m sáº¡ch dá»¯ liá»‡u ká»¹
    """)

# ========== DOWNLOAD MÃ” HÃŒNH ==========
st.markdown("---")
st.markdown("### ğŸ’¾ LÆ¯U VÃ€ Táº¢I MÃ” HÃŒNH")

if st.button("ğŸ’¾ LÆ¯U MÃ” HÃŒNH HOÃ€N CHá»ˆNH", type="primary"):
    try:
        # LÆ°u model vÃ  dá»¯ liá»‡u
        model_data = {
            'movies': movies,
            'cosine_sim': st.session_state.get('cosine_sim', None),
            'tfidf': st.session_state.get('tfidf', None)
        }
        
        with open('data/model_content_based.pkl', 'wb') as f:
            pickle.dump(model_data, f)
        
        st.success("âœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh hoÃ n chá»‰nh vÃ o data/model_content_based.pkl")
        st.balloons()
        
        # Hiá»ƒn thá»‹ thÃ´ng tin
        st.info("""
        **ğŸ“¦ CÃ¡c file Ä‘Ã£ lÆ°u:**
        1. `data/movies_final.csv` - Dá»¯ liá»‡u phim
        2. `data/cosine_sim.pkl` - Ma tráº­n similarity
        3. `data/model_content_based.pkl` - Full model
        
        **ğŸš€ MÃ´ hÃ¬nh sáºµn sÃ ng cho:**
        - Triá»ƒn khai há»‡ thá»‘ng gá»£i Ã
        - TÃ­ch há»£p vÃ o á»©ng dá»¥ng
        - Demo cho ngÆ°á»i dÃ¹ng
        """)
        
    except Exception as e:
        st.error(f"Lá»—i khi lÆ°u model: {e}")

# ========== NEXT STEPS ==========
st.markdown("---")
st.markdown("### ğŸ“ˆ BÆ¯á»šC TIáº¾P THEO")

col_next1, col_next2, col_next3 = st.columns(3)

with col_next1:
    st.markdown("""
    #### ğŸ§ª ÄÃNH GIÃ MÃ” HÃŒNH
    - Precision@K, Recall@K
    - A/B testing
    - User feedback
    """)

with col_next2:
    st.markdown("""
    #### ğŸ”— Káº¾T Há»¢P MÃ” HÃŒNH
    - Hybrid vá»›i Collaborative
    - ThÃªm popularity factor
    - Time-based filtering
    """)

with col_next3:
    st.markdown("""
    #### ğŸš€ TRIá»‚N KHAI
    - API endpoints
    - Real-time recommendations
    - Scaling vá»›i Spark
    """)

st.success("""
### ğŸ‰ HOÃ€N THÃ€NH XÃ‚Y Dá»°NG MÃ” HÃŒNH CONTENT-BASED FILTERING!

**ğŸ“Š THÃ€NH QUáº¢:**
âœ… ÄÃ£ xÃ¢y dá»±ng pipeline hoÃ n chá»‰nh  
âœ… Xá»­ lÃ½ dá»¯ liá»‡u vá»›i TF-IDF  
âœ… TÃ­nh toÃ¡n Cosine Similarity  
âœ… Demo há»‡ thá»‘ng gá»£i Ã phim tÆ°Æ¡ng tá»±  
âœ… LÆ°u model Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng  

**ğŸ¯ Sáº´N SÃ€NG CHO:** ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh vÃ  tÃ­ch há»£p há»‡ thá»‘ng!
""")